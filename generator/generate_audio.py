import sys
import os
# ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å ´æ‰€ã‹ã‚‰ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ã‚’importå¯¾è±¡ã«è¿½åŠ 
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from pydub import AudioSegment
import io
import json
import requests
from pydub import AudioSegment
from pathlib import Path
from dotenv import load_dotenv
from common.misread_dict import apply_misread_corrections  # â† è¿½åŠ 


# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¨è¨­å®šã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³è¨˜éŒ²ï¼ˆå…±é€šå‡¦ç†ï¼‰
from common.backup_script import backup_script
backup_script(__file__)
from common.save_config import save_config_snapshot
save_config_snapshot()

# .envã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿ï¼ˆã‚¨ãƒ³ã‚¸ãƒ³URLã‚„è©±è€…IDç”¨ï¼‰
load_dotenv()

VOICEVOX_ENGINE_URL = os.getenv("VOICEVOX_ENGINE_URL", "http://localhost:50021")
SPEAKER_ID = int(os.getenv("VOICEROID_SPEAKER_ID", 1))

# ==== è¿½åŠ ã“ã“ã‹ã‚‰ï¼ˆãƒ«ãƒ“å¤‰æ›ï¼‰ ====
# èª­ã¿èª¤ã‚Šã‚’é˜²ããŸã‚ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’ã²ã‚‰ãŒãªã«å¤‰æ›ã™ã‚‹å‡¦ç†ã‚’è¿½åŠ 
from fugashi import Tagger

tagger = Tagger()

def convert_to_hiragana(text: str) -> str:
    """MeCabã‚’ä½¿ã£ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ã²ã‚‰ãŒãªã«å¤‰æ›ã™ã‚‹"""
    return "".join([word.feature.kana if word.feature.kana else word.surface for word in tagger(text)])
# ==== è¿½åŠ ã“ã“ã¾ã§ ====

# æœ€æ–°ã®å°æœ¬ï¼ˆ.txtï¼‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã—ã¦ãƒ‘ã‚¹ã‚’è¿”ã™
def find_latest_script_txt(base_dir="scripts_ok") -> Path:
    txt_files = list(Path(base_dir).rglob("*.txt"))
    if not txt_files:
        raise FileNotFoundError("å°æœ¬ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    return max(txt_files, key=lambda p: p.stat().st_mtime)

# å°æœ¬ãƒ†ã‚­ã‚¹ãƒˆã‚’æ™‚é–“ä»˜ãã‚»ãƒªãƒ•ã®ã‚·ãƒ¼ãƒ³å˜ä½ã«åˆ†å‰²ã™ã‚‹
def split_script_to_scenes(script_text: str) -> list[dict]:
    scenes = []
    blocks = script_text.strip().split("ï¼ˆ")
    for block in blocks[1:]:
        try:
            time_str, content = block.split("ï¼‰", 1)
            scenes.append({
                "start": time_str.strip(),  # å°æœ¬ä¸Šã®æ™‚åˆ»ï¼ˆæ–‡å­—åˆ—ï¼‰
                "text": content.strip()     # ã‚»ãƒªãƒ•å†…å®¹
            })
        except ValueError:
            continue
    return scenes

# ==== è¿½åŠ ã“ã“ã‹ã‚‰ï¼ˆåŠ©è©ã®èª­ã¿æ–¹è£œæ­£ï¼‰ ====
def fix_particle_pronunciation(text: str) -> str:
    """
    ã²ã‚‰ãŒãªãƒ†ã‚­ã‚¹ãƒˆã®ã†ã¡ã€åŠ©è©ã§ä½¿ã‚ã‚Œã‚‹ã€Œã¯ã€ã€Œã¸ã€ã€Œã‚’ã€ã‚’
    ç™ºéŸ³ã«åˆã‚ã›ã¦ã€Œã‚ã€ã€Œãˆã€ã€ŒãŠã€ã«å¤‰æ›ã™ã‚‹ï¼ˆè¡¨è¨˜ã¯å¤‰ãˆãšã«éŸ³å£°ç”¨ã«èª¿æ•´ï¼‰
    """
    tokens = tagger(text)
    result = []
    for token in tokens:
        surface = token.surface
        pos = token.feature[0]  # â† ä¸»å“è©ï¼ˆ"åŠ©è©" ãªã©ï¼‰

        if pos == 'åŠ©è©':
            if surface == 'ã¯':
                result.append('ã‚')
                continue
            elif surface == 'ã¸':
                result.append('ãˆ')
                continue
            elif surface == 'ã‚’':
                result.append('ãŠ')
                continue

        result.append(surface)

    return ''.join(result)
# ==== è¿½åŠ ã“ã“ã¾ã§ ====


# VOICEVOXã‚¨ãƒ³ã‚¸ãƒ³ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’é€ä¿¡ã—ã¦éŸ³å£°ï¼ˆmp3ï¼‰ã‚’ç”Ÿæˆ
def synthesize_voice(text: str, output_path: Path):
    # ==== ä¿®æ­£ã“ã“ã‹ã‚‰ ====
    # textã‚’ã²ã‚‰ãŒãªã«å¤‰æ›ã—ã€åŠ©è©ã®èª­ã¿é–“é•ã„ã‚‚è£œæ­£ã™ã‚‹
    text = apply_misread_corrections(text)  # â† è¾æ›¸é©ç”¨ã‚’å…ˆã«
    hiragana_text = convert_to_hiragana(text)
    hiragana_text = fix_particle_pronunciation(hiragana_text)
    query_payload = {"text": hiragana_text, "speaker": SPEAKER_ID}
    # ==== ä¿®æ­£ã“ã“ã¾ã§ ====

    # éŸ³å£°åˆæˆã®ãŸã‚ã®ã‚¯ã‚¨ãƒªå–å¾—
    query_res = requests.post(f"{VOICEVOX_ENGINE_URL}/audio_query", params=query_payload)
    if query_res.status_code != 200:
        raise RuntimeError(f"éŸ³å£°ã‚¯ã‚¨ãƒªå¤±æ•—: {query_res.text}")

    # ã‚¯ã‚¨ãƒªã«éŸ³å£°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¿½åŠ ï¼ˆé€Ÿåº¦ãƒ»æŠ‘æšï¼‰
    query_data = query_res.json()
    query_data["speedScale"] = 1.3          # 1.5ã¯é€Ÿã™ãã‚‹å‚¾å‘ã€1.3ãã‚‰ã„ãŒè‡ªç„¶ã‹ã¤ãƒ†ãƒ³ãƒè‰¯ã—
    query_data["intonationScale"] = 1.2     # 1.5ã ã¨èŠå±…ãŒã‹ã‚Šã™ãã‚‹æã‚Œã‚ã‚Š
    query_data["pitchScale"] = 0.0          # å£°ã®é«˜ã•ã¯è‡ªç„¶ãªã¾ã¾ã§OK
    query_data["volumeScale"] = 1.0
    query_data["prePhonemeLength"] = 0.1    # ç™ºéŸ³å‰ã®ç„¡éŸ³èª¿æ•´ã§æ»‘ã‚‰ã‹ã«
    query_data["postPhonemeLength"] = 0.1   # ç™ºéŸ³å¾Œã®ç„¡éŸ³èª¿æ•´ã§ãƒ–ãƒ„åˆ‡ã‚Œå¯¾ç­–


    # åˆæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    synthesis_res = requests.post(
        f"{VOICEVOX_ENGINE_URL}/synthesis",
        params={"speaker": SPEAKER_ID},
        data=json.dumps(query_data),
        headers={"Content-Type": "application/json"}
    )
    if synthesis_res.status_code != 200:
        raise RuntimeError(f"éŸ³å£°åˆæˆå¤±æ•—: {synthesis_res.text}")

    # å‡ºåŠ›ä¿å­˜
    with open(output_path, "wb") as f:
        f.write(synthesis_res.content)

# mp3ãƒ•ã‚¡ã‚¤ãƒ«ã‚’wavå½¢å¼ã«å¤‰æ›ï¼ˆæœ«å°¾ã«ç„¡éŸ³è¿½åŠ ï¼‰
def convert_to_wav(mp3_path: Path, wav_path: Path):
    sound = AudioSegment.from_file(mp3_path)
    sound += AudioSegment.silent(duration=100)  # 100msã®ç„¡éŸ³è¿½åŠ 
    sound.export(wav_path, format="wav")


def main():
    # æœ€æ–°ã®å°æœ¬ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ã—ã¦å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
    latest_script_path = find_latest_script_txt()
    script_id = latest_script_path.stem.zfill(6)
    output_dir = Path(f"audio/{script_id}")
    output_dir.mkdir(parents=True, exist_ok=True)

    print(f"ğŸ¯ å°æœ¬èª­ã¿è¾¼ã¿: {latest_script_path}")
    with open(latest_script_path, encoding="utf-8") as f:
        script = f.read()

    # å°æœ¬ã‚’ã‚·ãƒ¼ãƒ³ã«åˆ†å‰²
    scenes = split_script_to_scenes(script)
    scene_timings = []   # ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ï¼ˆã‚·ãƒ¼ãƒ³ã”ã¨ï¼‰
    elapsed = 0.0        # å„ã‚·ãƒ¼ãƒ³ã®é–‹å§‹ç§’æ•°ï¼ˆç´¯ç©ï¼‰

    # å„ã‚·ãƒ¼ãƒ³ã”ã¨ã«éŸ³å£°ç”Ÿæˆã€wavå¤‰æ›ã€é•·ã•å–å¾—
    for i, scene in enumerate(scenes, start=1):
        scene_id = f"scene_{i:02}"
        mp3_path = output_dir / f"{scene_id}.mp3"
        wav_path = output_dir / f"{scene_id}.wav"
        print(f"ğŸ—£ï¸ {scene_id} - éŸ³å£°ç”Ÿæˆ: {scene['text'][:15]}...")

        try:
            # éŸ³å£°ç”Ÿæˆã¨å¤‰æ›
            synthesize_voice(scene["text"], mp3_path)
            convert_to_wav(mp3_path, wav_path)
            duration = AudioSegment.from_file(mp3_path).duration_seconds

            # ç¾åœ¨ã®ã‚·ãƒ¼ãƒ³ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’è¨˜éŒ²
            scene_timings.append({
                "scene_id": scene_id,
                "start_sec": round(elapsed, 2),     # å®Ÿéš›ã®é–‹å§‹ç§’ï¼ˆfloatï¼‰
                "duration": round(duration, 2),     # éŸ³å£°ã®é•·ã•
                "text": scene["text"]
            })

            elapsed += duration  # æ¬¡ã®ã‚·ãƒ¼ãƒ³ã®é–‹å§‹ç§’ã«åŠ ç®—
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼ ({scene_id}): {e}")

    # ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã‚’JSONã«ä¿å­˜ï¼ˆå¾Œå·¥ç¨‹ã§å…±é€šä½¿ç”¨ï¼‰
    timing_path = output_dir / "timing.json"
    with open(timing_path, "w", encoding="utf-8") as f:
        json.dump(scene_timings, f, ensure_ascii=False, indent=2)
    print(f"âœ… ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ä¿å­˜å®Œäº†: {timing_path}")

if __name__ == "__main__":
    main()
