import os
import json
import re
from openai import OpenAI
# ä¿®æ­£å¾Œï¼ˆãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ãƒ«ãƒ¼ãƒˆã« `sys.path` ã‚’é€šã—ã¦ã‚ã‚‹å‰æï¼‰
import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from PIL import Image
from pathlib import Path
import requests
import base64
import io


client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

PROMPT_DIR = "prompts/image/prompt_generator/"

def load_prompt_template(filename: str) -> str:
    path = os.path.join(PROMPT_DIR, filename)
    with open(path, "r", encoding="utf-8") as f:
        return f.read()

def call_gpt(user_prompt: str) -> str:
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.3
    )
    return response.choices[0].message.content.strip()

def collect_text_for_scene(script_id, parent_id):
    tag_path = Path(f"data/stage_2_tag/tags_{script_id}.json")
    print(f"ğŸ“‚ èª­ã¿è¾¼ã¿å¯¾è±¡: {tag_path}")

    if not tag_path.exists():
        raise FileNotFoundError(f"{tag_path} not found")

    with open(tag_path, "r", encoding="utf-8") as f:
        tags = json.load(f)
        print(f"ğŸ“¦ èª­ã¿è¾¼ã¿å‹: {type(tags)}")
        if isinstance(tags, list):
            print(f"ğŸ“„ ä»¶æ•°: {len(tags)}")
        else:
            print(f"âš ï¸ æƒ³å®šå¤–ã®ãƒ‡ãƒ¼ã‚¿: {str(tags)[:100]}")

    texts = [
        item["text"] for item in tags
        if isinstance(item, dict) and item.get("parent_scene_id") == parent_id
    ]

    print(f"ğŸ“ æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆæ•°: {len(texts)}")
    return "\n".join(texts)

def run_theme_reader(input_text: str) -> str:
    template = load_prompt_template("ThemeRader.txt")
    user_prompt = template.replace("ã€Œ{input_text}ã€", input_text)
    return call_gpt(user_prompt)


def run_prompt_crafter(composition: str) -> str:
    template = load_prompt_template("PromptCrafter.txt")
    user_prompt = template.replace("ã€Œ{composition}ã€", composition)
    return call_gpt(user_prompt)


def run_image_critic(composition: str, image_info: str) -> str:
    template = load_prompt_template("ImageCritic.txt")
    user_prompt = (
        template
        .replace("ã€Œ{composition}ã€", composition)
        .replace("ã€Œ{image_info}ã€", image_info)
    )
    return call_gpt(user_prompt)


def run_image_improver(original_prompt: str, composition: str, feedback: str) -> str:
    template = load_prompt_template("ImageImprover.txt")
    user_prompt = (
        template
        .replace("ã€Œ{original_prompt}ã€", original_prompt)
        .replace("ã€Œ{composition}ã€", composition)
        .replace("ã€Œ{feedback}ã€", feedback)
    )
    return call_gpt(user_prompt)


def run_finalizer(composition: str, image_list: list[str], feedbacks: list[str]) -> str:
    template = load_prompt_template("Finalizer.txt")
    image_block = "\n".join([f"{i+1}: {img}" for i, img in enumerate(image_list)])
    feedback_block = "\n".join([f"{i+1}: {fb}" for i, fb in enumerate(feedbacks)])

    user_prompt = (
        template
        .replace("ã€Œ{composition}ã€", composition)
        .replace("ã€Œ{image_list}ã€", image_block)
        .replace("ã€Œ{feedbacks}ã€", feedback_block)
    )
    return call_gpt(user_prompt)

def generate_image(prompt: str, num_images: int = 1) -> list[Image.Image]:
    results = []
    for i in range(num_images):
        try:
            img = generate_sd_image(prompt, negative_prompt="")
            results.append(img)
        except Exception as e:
            print(f"âŒ ç”»åƒç”Ÿæˆã«å¤±æ•—ï¼ˆ{i+1}/{num_images}ï¼‰: {e}")
            raise  # â† ã“ã“ã§å¿…ãšæ­¢ã‚ã‚‹
    return results
# ä¿®æ­£æ¸ˆã¿ generate_sd_image
def generate_sd_image(prompt: str, negative_prompt: str, port: int = 7860) -> Image.Image:
    

    print("âœ… generate_sd_image ã«å…¥ã£ãŸ")

    payload = {
        "prompt": prompt,
        "negative_prompt": negative_prompt,
        "model": "RealisticVisionXL_v57 [49E4F2939A]",
        "width": 1024,
        "height": 1024,
        "steps": 45,
        "cfg_scale": 8.0,
        "sampler_index": "DPM++ 2M Karras",
    }

    url = f"http://127.0.0.1:{port}/sdapi/v1/txt2img"  # âœ… ã“ã“ã« port ã‚’åæ˜ 

    try:
        response = requests.post(url, json=payload, timeout=1500)
        print("ğŸ”µ ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹:", response.status_code)
        print("ğŸ”µ ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆ:", response.text[:500])  # é•·ã™ãã‚‹å ´åˆã®å¯¾ç­–

        r = response.json()
        print("ğŸ”µ JSONå‹:", type(r))

        if not isinstance(r, dict):
            raise TypeError(f"JSON expected dict but got: {type(r)}\nå†…å®¹: {r}")

        images = r.get("images", [])
    except Exception as e:
        raise RuntimeError(f"ğŸš¨ SD APIå‘¼ã³å‡ºã— or JSONè§£æã«å¤±æ•— â†’ {e}")

    if not images or not images[0].strip():
        raise RuntimeError(f"No usable image returned. SD API response: {r}")

    try:
        raw_image = images[0].strip()
        base64_data = raw_image.split(",", 1)[-1] if "," in raw_image else raw_image
        decoded = base64.b64decode(base64_data)
        image = Image.open(io.BytesIO(decoded))
        image.load()
        return image
    except Exception as e:
        raise RuntimeError(f"Base64 decode or Image.open failed â†’ {e}")

def get_image_for_scene(script_id: str, parent_id: str) -> Image.Image:
    print(f"ğŸš© get_image_for_scene CALLED with script_id={script_id}, parent_id={parent_id}")
    try:
        text = collect_text_for_scene(script_id, parent_id)
        print(f"ğŸ“ collected text: {text[:50]}...")  # é•·ã„å ´åˆç”¨ã«çœç•¥
        image = persona_pipeline(text)
        print("âœ… persona_pipeline completed:", type(image))
        if not isinstance(image, Image.Image):
            raise TypeError(f"persona_pipeline did not return an Image: got {type(image)}")

        return image
    except Exception as e:
        print(f"ğŸ’¥ get_image_for_scene exception: {type(e).__name__}: {e}")
        raise  # ä¸Šä½ã® try ã«æ¸¡ã™


def persona_pipeline(text: str):
    print("â‘  æ§‹å›³æŠ½å‡º é–‹å§‹")
    composition = run_theme_reader(text)
    print("â‘  æ§‹å›³æŠ½å‡º å®Œäº†:", composition)

    print("â‘¡ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ é–‹å§‹")
    prompt = run_prompt_crafter(composition)
    print("â‘¡ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ å®Œäº†:", prompt)

    print("â‘¢ åˆæœŸç”»åƒç”Ÿæˆ é–‹å§‹")
    images = generate_image(prompt, num_images=2)
    print("âœ… ç”»åƒç”Ÿæˆå¾Œã®å‹:", [type(img) for img in images])

    # â‘£ è©•ä¾¡
    feedbacks = [run_image_critic(composition, "N/A") for _ in images]
    print("âœ… ç”»åƒç”Ÿæˆå¾Œã®å‹:", [type(img) for img in images])

    # â‘¤ æ”¹å–„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
    improved_prompt = run_image_improver(prompt, composition, feedbacks[0])

    # â‘¥ å†ç”Ÿæˆ
    improved = generate_image(improved_prompt, num_images=1)
    images += improved
    feedbacks = [run_image_critic(composition, "N/A") for _ in images]

    # â‘¦ æœ€çµ‚é¸å®š
    final_choice = run_finalizer(composition, [f"Image {i+1}" for i in range(len(images))], feedbacks)

    # é¸å®šã•ã‚ŒãŸç”»åƒã‚’è¿”ã™
    match = re.search(r'\d+', final_choice)
    if match:
        index = int(match.group())
        if 1 <= index <= len(images):
            if isinstance(images[index - 1], Image.Image):
                return images[index - 1]
            else:
                raise TypeError(f"Final selection is not an image: {type(images[index - 1])}")
        else:
            raise RuntimeError(f"Failed to parse final image selection: '{final_choice}'")
