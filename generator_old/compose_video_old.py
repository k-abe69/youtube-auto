import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import json
import numpy as np
import re

from moviepy.editor import *
from moviepy.video.fx.all import fadein
from common.constants import SILENCE_DURATION
from pathlib import Path
from dotenv import load_dotenv
from common.backup_script import backup_script
from common.save_config import save_config_snapshot
from common.script_utils import find_oldest_script_id, resolve_script_id 
from PIL import Image
from common.video_export import export_video_high_quality

from datetime import datetime, timedelta
from collections import defaultdict


# åˆæœŸå‡¦ç†
backup_script(__file__)
save_config_snapshot()
load_dotenv()

# å®šæ•°
VIDEO_WIDTH = 720
VIDEO_HEIGHT = 1280




def parse_srt_time(t: str) -> float:
    dt = datetime.strptime(t.strip(), "%H:%M:%S,%f")
    return timedelta(
        hours=dt.hour,
        minutes=dt.minute,
        seconds=dt.second,
        microseconds=dt.microsecond
    ).total_seconds()

def check_srt_overlaps(srt_path: Path):
    print("\nğŸ§ å­—å¹•ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ãƒã‚§ãƒƒã‚¯é–‹å§‹")
    with open(srt_path, "r", encoding="utf-8") as f:
        content = f.read()

    entries = re.findall(r"(\d+)\n(\d{2}:\d{2}:\d{2},\d{3}) --> (\d{2}:\d{2}:\d{2},\d{3})\n", content)

    prev_end = 0
    for idx, (_, start_str, end_str) in enumerate(entries):
        start_sec = parse_srt_time(start_str)
        end_sec = parse_srt_time(end_str)

        if start_sec < prev_end:
            print(f"âš ï¸ é‡è¤‡: #{idx+1} start={start_sec:.3f}s overlaps with previous end={prev_end:.3f}s")
        prev_end = end_sec

    print("âœ… å­—å¹•ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ãƒã‚§ãƒƒã‚¯å®Œäº†\n")

def compose_video(script_id: str):
    timing_path = Path(f"data/stage_2_tag/tags_{script_id}.json")
    subtitle_path = Path(f"data/stage_4_subtitles/subtitles_{script_id}.srt")
    audio_base_dir = Path(f"data/stage_1_audio/{script_id}")
    image_base_dir = Path(f"data/stage_3_images/{script_id}")
    output_dir = Path(f"data/stage_5_output/{script_id}")
    output_dir.mkdir(parents=True, exist_ok=True)

    with open(timing_path, "r", encoding="utf-8") as f:
        data = json.load(f)
        scenes = data["scenes"]

    clips = []
    audio_clips = []
    current_start = 0.0  # ç´¯ç©å‹ã®å†ç”Ÿé–‹å§‹æ™‚åˆ»ï¼ˆã™ã¹ã¦ã®åŸºæº–ï¼‰

    # âœ… parent_scene_id ã”ã¨ã«èƒŒæ™¯ç”»åƒã‚’è¡¨ç¤º
    from collections import defaultdict

    # âœ… parent_scene_id ã”ã¨ã«èƒŒæ™¯ç”»åƒã‚’è¡¨ç¤ºï¼ˆéŸ³å£°ã¨å®Œå…¨åŒæœŸã•ã›ã‚‹ï¼‰
    parent_scene_map = defaultdict(list)
    for scene in scenes:
        parent_scene_map[scene["parent_scene_id"]].append(scene)

    timeline_pointer = 0.0  # ç”»åƒè¡¨ç¤ºã®ç´¯ç©é–‹å§‹æ™‚é–“ã€‚éŸ³å£°ã¨åŒã˜ãå‰ã‹ã‚‰é †ã«ç©ã¿ä¸Šã’ã¦ã„ã

    for parent_id, group in parent_scene_map.items():
        img_path = image_base_dir / f"{parent_id}.jpg"

        if not img_path.exists():
            print(f"âš ï¸ ã‚¹ã‚­ãƒƒãƒ—: parent_scene_id={parent_id}ï¼ˆç”»åƒãŒè¦‹ã¤ã‹ã‚‰ãªã„ï¼‰")
            continue

        # âœ… ãã®ã‚°ãƒ«ãƒ¼ãƒ—ã«å«ã¾ã‚Œã‚‹å„ scene_id.wav ã®å†ç”Ÿæ™‚é–“ï¼ˆï¼‹SILENCEï¼‰ã‚’ç©ç®—
        group_duration = 0.0
        for scene in group:
            audio_path = audio_base_dir / f"{scene['scene_id']}.wav"
            if not audio_path.exists():
                continue
            audio_clip = AudioFileClip(str(audio_path))
            group_duration += audio_clip.duration + SILENCE_DURATION

        # âœ… ã“ã®è¦ªsceneã®ç”»åƒã‚’è¡¨ç¤ºã™ã‚‹é–‹å§‹æ™‚åˆ»ã¨è¡¨ç¤ºæ™‚é–“ã‚’æ±ºå®šï¼ˆï¼éŸ³å£°ã¨å®Œå…¨ä¸€è‡´ï¼‰
        start_time = timeline_pointer
        duration = group_duration
        end_time = start_time + duration
        timeline_pointer = end_time  # æ¬¡ã®è¦ªsceneã®ç”»åƒè¡¨ç¤ºé–‹å§‹æ™‚é–“ã«æ›´æ–°

        # âœ… èƒŒæ™¯ç”»åƒã‚’è¨­å®šï¼ˆå…¨ç”»é¢ã€ã‚»ãƒ³ã‚¿ãƒ¼ã€durationã¶ã‚“è¡¨ç¤ºï¼‰
        image_clip = (
            ImageClip(str(img_path))
            .resize((VIDEO_WIDTH, VIDEO_HEIGHT))
            .set_position("center")
            .set_duration(duration)
            .set_start(start_time)
        )

        # âœ… å†’é ­ã‚·ãƒ¼ãƒ³ã ã‘ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³æ¼”å‡ºã‚’é©ç”¨
        if parent_id == "000":
            image_clip = image_clip.fx(fadein, 0.3)

        if clips:
            # å‰ã® clip ã® end_time ã‚’å–å¾—
            prev_clip = clips[-1]
            crossfade_duration = 0.1  # ç§’æ•°ï¼ˆè‡ªç„¶ãªãƒ•ã‚§ãƒ¼ãƒ‰æ¨å¥¨ï¼‰

            # å‰ã®clipã«ã‚¯ãƒ­ã‚¹ãƒ•ã‚§ãƒ¼ãƒ‰é©ç”¨
            prev_clip = prev_clip.crossfadeout(crossfade_duration)
            image_clip = image_clip.crossfadein(crossfade_duration)

            # å·®ã—æ›¿ãˆ
            clips[-1] = prev_clip

        clips.append(image_clip)


    for i, scene in enumerate(scenes):
        scene_id = scene["scene_id"]
        audio_path = audio_base_dir / f"{scene_id}.wav"

        if not audio_path.exists():
            print(f"âš ï¸ ã‚¹ã‚­ãƒƒãƒ—: {scene_id}ï¼ˆç”»åƒã¾ãŸã¯éŸ³å£°ãŒè¦‹ã¤ã‹ã‚‰ãªã„ï¼‰")
            continue

        # éŸ³å£°èª­ã¿è¾¼ã¿ + ç„¡éŸ³0ç§’è¿½åŠ 
        audio_clip = AudioFileClip(str(audio_path))
        silence = AudioClip(make_frame=lambda t: [0], duration=SILENCE_DURATION, fps=44100).set_fps(44100)
        audio_clip = concatenate_audioclips([audio_clip, silence])
        real_duration = audio_clip.duration  # SILENCE_DURATIONã‚’å«ã‚€

        # å®‰å…¨ãªæ™‚é–“å®šç¾©
        start_time = current_start
        end_time = start_time + real_duration
        duration = end_time - start_time  # â† duration ã‚’å…ˆã«å®šç¾©ï¼


        # éŸ³å£°clipï¼ˆæ˜ç¤ºçš„ã«start/endã‚’æŒ‡å®šï¼‰
        audio_clip = audio_clip.set_start(start_time).set_end(end_time)
        audio_clips.append(audio_clip)

        current_start = end_time  # æ¬¡ã®sceneã®åŸºæº–æ™‚é–“ã«é€²ã‚ã‚‹

    if not clips:
        print("âŒ æœ‰åŠ¹ãªsceneãŒã‚ã‚Šã¾ã›ã‚“ã€‚å‹•ç”»ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã€‚")
        return

    final_audio = concatenate_audioclips(audio_clips)

    # ãƒãƒ©ã¤ãå¯¾ç­–
    final = CompositeVideoClip(clips, size=(VIDEO_WIDTH, VIDEO_HEIGHT)).set_audio(final_audio)

    temp_path = output_dir / "no_subtitles.mp4"
    export_video_high_quality(final, str(temp_path))

    final_path = output_dir / "final.mp4"

    if subtitle_path.exists():
        check_srt_overlaps(subtitle_path)

        ffmpeg_command = (
            f'ffmpeg -y -hwaccel cuda -i "{temp_path}" '
            f'-vf "subtitles=\'{subtitle_path.as_posix()}\':force_style='
            f'\'Fontname=Noto Sans CJK JP, Alignment=2,Fontsize=18,Outline=2,MarginV=80,Shadow=1, '
            f'PrimaryColour=&H00FFFFFF,OutlineColour=&H00000000,ShadowColour=&H80000000,BorderStyle=1, LineSpacing=0\'" '
            f'-c:v h264_nvenc -preset slow -b:v 4000k -maxrate 4000k -bufsize 8000k '
            f'-pix_fmt yuv420p -profile:v baseline -level 4.0 '
            f'-c:a aac -b:a 128k -ar 44100 -ac 2 '
            f'"{final_path}"'
        )
        print(f"[GPUå­—å¹•ç„¼ãè¾¼ã¿] {ffmpeg_command}")
        ret = os.system(ffmpeg_command)
        if ret != 0:
            raise RuntimeError(f"âŒ å­—å¹•ç„¼ãè¾¼ã¿ffmpegå‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆcode={ret}ï¼‰")
        print(f"âœ… å­—å¹•ä»˜ãå‹•ç”»ã‚’GPUã§ä¿å­˜ã—ã¾ã—ãŸ: {final_path}")

    else:
        print(f"âš ï¸ å­—å¹•ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å­—å¹•ãªã—ã§ä¿å­˜: {temp_path}")
        temp_path.rename(final_path)

    compatible_path = output_dir / "final_compatible.mp4"
    ffmpeg_compat_cmd = (
        f'ffmpeg -y -hwaccel cuda -i "{final_path}" '
        f'-vf "scale=trunc(iw/2)*2:trunc(ih/2)*2,format=yuv420p" '
        f'-c:v h264_nvenc -preset slow -b:v 4000k -maxrate 4000k -bufsize 8000k -pix_fmt yuv420p '
        f'-profile:v baseline -level 4.0 '
        f'-c:a aac -b:a 128k -ar 44100 -ac 2 '
        f'"{compatible_path}"'
    )


    print(f"[GPUäº’æ›å¤‰æ›] {ffmpeg_compat_cmd}")
    os.system(ffmpeg_compat_cmd)
    print(f"âœ… å†ç”Ÿäº’æ›ç‰ˆå‹•ç”»ï¼ˆGPUä½¿ç”¨ï¼‰ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {compatible_path}")


if __name__ == "__main__":
    script_id = resolve_script_id()
    compose_video(script_id)
