import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import json
import random
import requests
import shutil
import base64
import io

from PIL import Image
from pathlib import Path
from urllib.parse import quote
from common.backup_script import backup_script
from common.save_config import save_config_snapshot
from common.script_utils import extract_script_id, find_oldest_script_file, find_oldest_script_id, resolve_script_id   # â† ä¿®æ­£ç‚¹

backup_script(__file__)
save_config_snapshot()

from dotenv import load_dotenv
load_dotenv()

from PIL import Image
import imagehash
from io import BytesIO

PIXABAY_API_KEY = os.getenv("PIXABAY_API_KEY")
if not PIXABAY_API_KEY:
    raise ValueError("Pixabayã®APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ (.envã«PIXABAY_API_KEYã‚’è¿½åŠ )")

UNSPLASH_ACCESS_KEY = os.getenv("UNSPLASH_ACCESS_KEY")
if not UNSPLASH_ACCESS_KEY:
    raise ValueError("Unsplashã®APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ (.envã«UNSPLASH_ACCESS_KEYã‚’è¿½åŠ )")


def fetch_image_url_pixabay(tags: list, used_urls: set, used_hashes: set) -> str:
    query = "+".join([quote(tag) for tag in tags])
    url = f"https://pixabay.com/api/?key={PIXABAY_API_KEY}&q={query}&image_type=photo&orientation=vertical&per_page=10"
    res = requests.get(url)
    if res.status_code != 200:
        raise RuntimeError(f"Pixabayãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—: {res.text}")
    data = res.json()
    hits = data.get("hits", [])

    for hit in hits:
        image_url = hit["largeImageURL"]
        if image_url in used_urls:
            continue

        try:
            response = requests.get(image_url)
            img = Image.open(BytesIO(response.content)).convert("RGB")
            hash_val = imagehash.phash(img)
            is_duplicate = any(existing - hash_val <= 5 for existing in used_hashes)
            if is_duplicate:
                print(f"[SKIP] é¡ä¼¼ç”»åƒã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—: {image_url}")
                continue

            used_urls.add(image_url)
            used_hashes.add(hash_val)
            return image_url
        except Exception as e:
            print(f"[ERROR] ãƒãƒƒã‚·ãƒ¥ç”Ÿæˆå¤±æ•—: {e}")
            continue

    return ""

def fetch_image_url_unsplash(tags: list, used_urls: set, used_hashes: set) -> str:
    """
    Unsplash API ã‚’ä½¿ã£ã¦ç”»åƒã‚’1æšæ¤œç´¢ãƒ»æ¤œè¨¼ã—ã€æœ‰åŠ¹ãªç”»åƒURLã‚’è¿”ã™ã€‚
    é¡ä¼¼ç”»åƒã®é‡è¤‡ã¯é™¤å¤–ã•ã‚Œã‚‹ã€‚

    Parameters:
        tags (list): æ¤œç´¢ã«ä½¿ã†ã‚¿ã‚°ãƒªã‚¹ãƒˆï¼ˆä¾‹: ["smile", "gentle"]ï¼‰
        used_urls (set): ã™ã§ã«ä½¿ç”¨æ¸ˆã¿ã®ç”»åƒURLé›†åˆï¼ˆé‡è¤‡é˜²æ­¢ï¼‰
        used_hashes (set): ã™ã§ã«ä½¿ç”¨æ¸ˆã¿ã®ç”»åƒãƒãƒƒã‚·ãƒ¥é›†åˆï¼ˆé¡ä¼¼é™¤å¤–ï¼‰

    Returns:
        str: æœ‰åŠ¹ãªç”»åƒURLï¼ˆè¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã°ç©ºæ–‡å­—ï¼‰
    """
    if not UNSPLASH_ACCESS_KEY:
        raise ValueError("Unsplashã®APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ (.envã«UNSPLASH_ACCESS_KEYã‚’è¿½åŠ )")

    # ã‚¯ã‚¨ãƒªæ§‹ç¯‰ï¼ˆç©ºç™½åŒºåˆ‡ã‚Šï¼‰
    query = " ".join(tags)
    url = "https://api.unsplash.com/photos/random"
    params = {
        "query": query,
        "client_id": UNSPLASH_ACCESS_KEY,
        "orientation": "portrait",         # TikTok/ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»å‘ã‘ç¸¦å‹
        "content_filter": "high"           # å“è³ªãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    }

    try:
        res = requests.get(url, params=params)
        if res.status_code != 200:
            print(f"âŒ Unsplashãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—: {res.status_code} / {res.text}")
            return ""

        data = res.json()
        image_url = data.get("urls", {}).get("regular")

        if not image_url or image_url in used_urls:
            return ""
        
        # ğŸ” ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¤ãƒ™ãƒ³ãƒˆã‚’é€ä¿¡ï¼ˆãƒãƒªã‚·ãƒ¼å¿…é ˆï¼‰
        if download_location:
            try:
                requests.get(download_location, params={"client_id": UNSPLASH_ACCESS_KEY})
            except Exception as e:
                print(f"[è­¦å‘Š] ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¤ãƒ™ãƒ³ãƒˆé€ä¿¡å¤±æ•—: {e}")


        # é¡ä¼¼ç”»åƒã®ãƒã‚§ãƒƒã‚¯ï¼ˆç”»åƒå–å¾— â†’ ãƒãƒƒã‚·ãƒ¥è¨ˆç®—ï¼‰
        response = requests.get(image_url)
        img = Image.open(BytesIO(response.content)).convert("RGB")
        hash_val = imagehash.phash(img)
        is_duplicate = any(existing - hash_val <= 5 for existing in used_hashes)

        if is_duplicate:
            print(f"[SKIP] é¡ä¼¼ç”»åƒã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—: {image_url}")
            return ""

        # ä½¿ç”¨å±¥æ­´ã«è¿½åŠ 
        used_urls.add(image_url)
        used_hashes.add(hash_val)
        return image_url

    except Exception as e:
        print(f"[ERROR] Unsplashç”»åƒå‡¦ç†ä¸­ã«ä¾‹å¤–: {e}")
    return ""

# ä¿®æ­£æ¸ˆã¿ generate_sd_image
def generate_sd_image(prompt: str, negative_prompt: str, port: int = 7860) -> Image.Image:
    payload = {
        "prompt": prompt,
        "negative_prompt": negative_prompt,
        "width": 512,
        "height": 768,
        "steps": 25,
        "sampler_index": "Euler a"
    }

    url = f"http://127.0.0.1:{port}/sdapi/v1/txt2img"  # âœ… ã“ã“ã« port ã‚’åæ˜ 

    response = requests.post(url, json=payload, timeout=600)
    r = response.json()
    images = r.get("images", [])

    if not images or not images[0].strip():
        raise RuntimeError(f"No usable image returned. SD API response: {r}")

    try:
        raw_image = images[0].strip()
        base64_data = raw_image.split(",", 1)[-1] if "," in raw_image else raw_image
        decoded = base64.b64decode(base64_data)
        image = Image.open(io.BytesIO(decoded))
        image.load()
        return image
    except Exception as e:
        raise RuntimeError(f"Base64 decode or Image.open failed â†’ {e}")


def download_image(url: str, save_path: Path):
    try:
        res = requests.get(url, timeout=10)
        res.raise_for_status()
        img = Image.open(io.BytesIO(res.content)).convert("RGB")
        img.save(save_path, format="JPEG")
        print(f"âœ… ç”»åƒä¿å­˜: {save_path}")
    except Exception as e:
        print(f"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {url} â†’ {e}")

def fetch_all_images(scene_json_path: Path, script_id: str):
    with open(scene_json_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    global_tag = data.get("global_image_tag", "")
    scenes = data.get("scenes", [])

    output_dir = Path(f"data/stage_3_images/{script_id}")
    output_dir.mkdir(parents=True, exist_ok=True)

    used_urls = set()
    used_hashes = set()

    # parent_scene_id ã”ã¨ã«ã¾ã¨ã‚ã‚‹
    parent_map = {}
    for scene in scenes:
        parent_id = scene["parent_scene_id"]
        parent_map.setdefault(parent_id, []).append(scene)

    # SDãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
    # with open(f"data/stage_2_tag/sd_{script_id}.json", "r", encoding="utf-8") as f:
    #     sd_prompts = json.load(f)

    # for i, (parent_id, prompt_data) in enumerate(sd_prompts.items()):
    #     prompt = prompt_data["prompt"]
    #     negative_prompt = prompt_data["negative_prompt"]

    #     out_dir = Path(f"data/stage_3_image/sd_images/{script_id}")
    #     out_dir.mkdir(parents=True, exist_ok=True)
    #     out_path = out_dir / f"{parent_id}.png"

    #     if out_path.exists():
    #         print(f"âœ… æ—¢ã«ç”Ÿæˆæ¸ˆã¿: {out_path}")
    #         continue

    #     try:
    #         print(f"[{i+1}/{len(sd_prompts)}] Generating image for parent_id={parent_id}")
    #         image = generate_sd_image(prompt, negative_prompt, port=7860)
    #         image.save(out_path)
    #         print(f"ğŸ§  SDç”»åƒä¿å­˜å®Œäº†: {out_path}")
    #     except Exception as e:
    #         print(f"âŒ SDç”»åƒç”Ÿæˆå¤±æ•—: {parent_id} â†’ {type(e).__name__}: {e}")

    for parent_id, group in parent_map.items():
        # ã‚°ãƒ«ãƒ¼ãƒ—å†…ã®å…¨ã‚¿ã‚°ã‚’é›†ã‚ã‚‹
        all_tags = [tag for scene in group for tag in scene.get("tags", [])]
        if global_tag and global_tag != "ãã®ä»–":
            all_tags.insert(0, global_tag)

        if not all_tags:
            print(f"âš ï¸ ã‚¿ã‚°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆparent_scene_id: {parent_id}ï¼‰")
            continue

        selected_tags = random.sample(all_tags, min(3, len(all_tags)))
        image_url = fetch_image_url_pixabay(selected_tags, used_urls, used_hashes)

        if image_url:
            print(f"[DEBUG] ä½¿ç”¨ç”»åƒURL: {image_url} â†’ parent_scene_id: {parent_id}")
            image_path = output_dir / f"{parent_id}.jpg"
            download_image(image_url, image_path)
        else:
            print(f"âš ï¸ æœ‰åŠ¹ãªç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {selected_tags} for parent_scene_id {parent_id}")


if __name__ == "__main__":
    input_dir = Path("data/stage_2_tag")
    output_dir = Path("data/stage_3_image")
    script_id = resolve_script_id()

    # ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¢ç´¢ã—ã€å„ä¸­ã«ã‚ã‚‹ .json ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†
    all_json_files = []
    # ä¿®æ­£å¾Œ
    json_files = list(input_dir.glob("tags_*.json"))
    all_json_files.extend(json_files)

    # å°æœ¬IDãŒå–ã‚Œã‚‹ã‚‚ã®ã ã‘ã«é™å®š
    valid_json_files = [f for f in all_json_files if extract_script_id(f.name)]
    valid_json_files.sort(key=lambda f: extract_script_id(f.name))

    if not valid_json_files:
        print("âŒ å‡¦ç†å¯èƒ½ãªJSONãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        exit()

    scene_json_file = input_dir / f"tags_{script_id}.json"
    print(f"[DEBUG] script_id = {script_id}")

    if not scene_json_file.exists():
        print(f"âŒ JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {scene_json_file}")
        exit()

    fetch_all_images(scene_json_path=scene_json_file, script_id=script_id)
