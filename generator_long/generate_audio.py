import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from pydub import AudioSegment
import io
import json
import requests
import re
from pathlib import Path
from dotenv import load_dotenv
from common.misread_dict import apply_misread_corrections
from fugashi import Tagger
import shutil
from common.script_utils import parse_args_script_id, mark_script_completed, get_next_script_id, parse_and_generate_voicevox_script

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()
VOICEVOX_ENGINE_URL = os.getenv("VOICEVOX_ENGINE_URL", "http://localhost:50021")
SPEAKER_ID = int(os.getenv("VOICEROID_SPEAKER_ID", 66))

# å½¢æ…‹ç´ è§£æå™¨ã®åˆæœŸåŒ–
tagger = Tagger()

# ãƒ†ã‚­ã‚¹ãƒˆã‚’ã²ã‚‰ãŒãªã«å¤‰æ›ã™ã‚‹é–¢æ•°
def convert_to_hiragana(text: str) -> str:
    return "".join([word.feature.kana if word.feature.kana else word.surface for word in tagger(text)])

# åŠ©è©ã®ç™ºéŸ³ã‚’ä¿®æ­£ã™ã‚‹é–¢æ•°
def fix_particle_pronunciation(text: str) -> str:
    tokens = tagger(text)
    result = []
    for token in tokens:
        surface = token.surface
        pos = token.feature[0]
        if pos == 'åŠ©è©':
            if surface == 'ã¯':
                result.append('ã‚')
                continue
            elif surface == 'ã¸':
                result.append('ãˆ')
                continue
            elif surface == 'ã‚’':
                result.append('ãŠ')
                continue
        result.append(surface)
    return ''.join(result)

# ã‚«ãƒŠã‹ãªå¤‰æ›
def kata_to_hira(text: str) -> str:
    return ''.join(
        chr(ord(char) - 0x60) if 'ã‚¡' <= char <= 'ãƒ³' else char
        for char in text
    )


# éŸ³å£°åˆæˆã‚’è¡Œã†é–¢æ•°
def synthesize_voice(text: str, output_path: Path):
    # ğŸ¯ æ”¹è¡Œã¯VOICEVOXã«æ¸¡ã™ã¨ã€Œãˆã¬ã€ã¨èª­ã¾ã‚Œã‚‹ãŸã‚ç©ºç™½ã«ç½®æ›
    text = text.replace("\\n", " ")  # â† ãƒãƒƒã‚¯ã‚¹ãƒ©ãƒƒã‚·ãƒ¥nï¼ˆ2æ–‡å­—ï¼‰ã‚’ç©ºç™½ã«
    text = text.replace("\n", " ")   # â† æ”¹è¡Œæ–‡å­—ï¼ˆ1æ–‡å­—ï¼‰ã‚‚ç©ºç™½ã«
    text = apply_misread_corrections(text)
    text = fix_particle_pronunciation(text)
    hiragana_text = convert_to_hiragana(text)
    hiragana_text = kata_to_hira(hiragana_text)  # â† ã‚«ã‚¿ã‚«ãƒŠâ†’ã²ã‚‰ãŒãª
    print(f"[TTSç”¨ãƒ†ã‚­ã‚¹ãƒˆ]: {hiragana_text}")
    query_payload = {"text": hiragana_text, "speaker": SPEAKER_ID}
    query_res = requests.post(f"{VOICEVOX_ENGINE_URL}/audio_query", params=query_payload)
    if query_res.status_code != 200:
        raise RuntimeError(f"éŸ³å£°ã‚¯ã‚¨ãƒªå¤±æ•—: {query_res.text}")
    query_data = query_res.json()
    # éŸ³å£°åˆæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®š
    query_data["speedScale"] = 1.45
    query_data["intonationScale"] = 1.2
    query_data["pitchScale"] = 0.0
    query_data["volumeScale"] = 1.0
    query_data["prePhonemeLength"] = 0.1
    query_data["postPhonemeLength"] = 0.1
    synthesis_res = requests.post(
        f"{VOICEVOX_ENGINE_URL}/synthesis",
        params={"speaker": SPEAKER_ID},
        data=json.dumps(query_data),
        headers={"Content-Type": "application/json"}
    )
    if synthesis_res.status_code != 200:
        raise RuntimeError(f"éŸ³å£°åˆæˆå¤±æ•—: {synthesis_res.text}")
    with open(output_path, "wb") as f:
        f.write(synthesis_res.content)

# mp3ã‚’wavã«å¤‰æ›ã™ã‚‹é–¢æ•°
def convert_to_wav(mp3_path: Path, wav_path: Path):
    sound = AudioSegment.from_file(mp3_path)
    sound += AudioSegment.silent(duration=100)
    sound.export(wav_path, format="wav")

# å°æœ¬ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚·ãƒ¼ãƒ³ã‚’åˆ†å‰²ã™ã‚‹é–¢æ•°
def split_script_to_scenes(script_text: str) -> list[dict]:
    scenes = []
    lines = script_text.splitlines()
    current_time = None
    current_text = []
    time_pattern = re.compile(r"[ï¼ˆ(ã€\[]\s*(\d+:\d+)\s*[ï¼‰)ã€‘\]]")
    for line in lines:
        match = time_pattern.match(line.strip())
        if match:
            if current_time and current_text:
                scenes.append({
                    "start": current_time,
                    "text": "\n".join(current_text).strip()
                })
            current_time = match.group(1)
            current_text = []
        else:
            current_text.append(line)
    if current_time and current_text:
        scenes.append({
            "start": current_time,
            "text": "\n".join(current_text).strip()
        })
    return scenes

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
def main():
    task_name = "audio"
    script_id = parse_args_script_id() or get_next_script_id(task_name)
    if script_id is None:
        return

    input_base_dir = Path("scripts")
    output_base_dir = Path("data_long/stage_1_audio")

    output_base_dir.mkdir(parents=True, exist_ok=True)

    script_txt_path = input_base_dir / f"script_{script_id}.txt"


    output_dir = output_base_dir / script_id
    output_dir.mkdir(parents=True, exist_ok=True)

    tmp_script_path = output_dir / f"script_for_voicevox_{script_id}.txt"
    tmp_meta_path = output_dir / f"script_meta_{script_id}.json"

    # ğŸ¯ ã“ã“ã§ (0:00) ä»˜ãã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ç”Ÿæˆ
    parse_and_generate_voicevox_script(script_txt_path, tmp_script_path, tmp_meta_path)

    print(f"ğŸ¯ å°æœ¬èª­ã¿è¾¼ã¿: {tmp_script_path}")
    with open(tmp_script_path, encoding="utf-8") as f:
        script = f.read()

    scenes = split_script_to_scenes(script)

    # ğŸ”½ ã“ã“ã§ãƒ¡ã‚¿æƒ…å ±ã‹ã‚‰ type ã‚’èª­ã¿è¾¼ã‚€ï¼ˆidåŸºæº–ï¼‰
    with open(tmp_meta_path, encoding="utf-8") as f:
        meta_data = json.load(f)
    scene_id_to_type = {}
    for entry in meta_data:
        if entry["type"] != "source":
            scene_id_to_type[entry["scene_id"]] = entry["type"]


    scene_timings = []
    elapsed = 0.0

    # å„ã‚·ãƒ¼ãƒ³ã®éŸ³å£°ã‚’ç”Ÿæˆã—ã€ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã‚’è¨˜éŒ²
    for i, scene in enumerate(scenes, start=1):
        scene_id = f"scene_{i:02}"
        mp3_path = output_dir / f"{scene_id}.mp3"
        wav_path = output_dir / f"{scene_id}.wav"
        print(f"ğŸ—£ï¸ {scene_id} - éŸ³å£°ç”Ÿæˆ: {scene['text'][:15]}...")

        try:
            synthesize_voice(scene["text"], mp3_path)
            convert_to_wav(mp3_path, wav_path)
            duration = AudioSegment.from_file(mp3_path).duration_seconds
            scene_timings.append({
                "scene_id": scene_id,
                "start_sec": round(elapsed, 2),
                "duration": round(duration, 2),
                "text": scene["text"],
                "type": scene_id_to_type.get(scene_id, "unknown")  # â† ã“ã‚Œã§å®Œå…¨ä¸€è‡´

            })
            elapsed += duration
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼ ({scene_id}): {e}")

    # ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã‚’ä¿å­˜
    timing_path = output_dir / f"timing_{script_id}.json"
    with open(timing_path, "w", encoding="utf-8") as f:
        json.dump(scene_timings, f, ensure_ascii=False, indent=2)
    print(f"âœ… ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ä¿å­˜å®Œäº†: {timing_path}")

    # ğŸ”½ scene_idã«åŸºã¥ã„ã¦metaã«æ™‚é–“æƒ…å ±ã‚’åŸ‹ã‚ã‚‹
    scene_id_to_timing = {
        s["scene_id"]: {
            "start_sec": s["start_sec"],
            "duration": s["duration"]
        }
        for s in scene_timings
    }

    for entry in meta_data:
        timing = scene_id_to_timing.get(entry["scene_id"])
        if timing:
            entry["start_sec"] = timing["start_sec"]
            entry["duration"] = timing["duration"]

    # ğŸ”½ ã‚¿ã‚¤ãƒŸãƒ³ã‚°ä»˜ãã®metaã‚’å†ä¿å­˜ï¼ˆå­—å¹•ç”¨ã«ä½¿ãˆã‚‹ï¼‰
    meta_path_with_timing = output_dir / f"script_meta_{script_id}.json"
    with open(meta_path_with_timing, "w", encoding="utf-8") as f:
        json.dump(meta_data, f, ensure_ascii=False, indent=2)
    print(f"âœ… ãƒ¡ã‚¿æƒ…å ±ï¼ˆã‚¿ã‚¤ãƒŸãƒ³ã‚°ä»˜ãï¼‰ä¿å­˜å®Œäº†: {meta_path_with_timing}")
    mark_script_completed(script_id, task_name)
    print(f"âœ… ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°å®Œäº†: {script_id} ã® {task_name} å®Œäº†")

if __name__ == "__main__":
    main()
