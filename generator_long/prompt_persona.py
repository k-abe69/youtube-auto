import os
import json
import re
from openai import OpenAI
# ä¿®æ­£å¾Œï¼ˆãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ãƒ«ãƒ¼ãƒˆã« `sys.path` ã‚’é€šã—ã¦ã‚ã‚‹å‰æï¼‰
import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from PIL import Image
from pathlib import Path
import requests
import base64
import io


client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

PROMPT_DIR = "prompts/image/prompt_generator/"

def load_prompt_template(filename: str) -> str:
    path = os.path.join(PROMPT_DIR, filename)
    with open(path, "r", encoding="utf-8") as f:
        return f.read()

def call_gpt(user_prompt: str) -> str:
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.7
    )
    return response.choices[0].message.content.strip()

def collect_text_for_scene(script_id, parent_id):
    tag_path = Path(f"data_long/stage_2_tag/tags_{script_id}.json")
    print(f"ðŸ“‚ èª­ã¿è¾¼ã¿å¯¾è±¡: {tag_path}")

    if not tag_path.exists():
        raise FileNotFoundError(f"{tag_path} not found")

    with open(tag_path, "r", encoding="utf-8") as f:
        data = json.load(f)
        print(f"ðŸ“¦ èª­ã¿è¾¼ã¿åž‹: {type(data)}")
        if not isinstance(data, dict) or "scenes" not in data:
            raise ValueError(f"ä¸æ­£ãªãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆ: scenesãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        scenes = data["scenes"]
        print(f"ðŸ“„ scenesã®æ•°: {len(scenes)}")

    texts = [
        item["text"] for item in scenes
        if item.get("parent_scene_id") == parent_id
    ]
    print(f"ðŸ“ æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆæ•°: {len(texts)}")
    return "\n".join(texts)

def run_theme_reader_multi(input_text: str, input_before: str, input_after: str) -> str:
    """è¤‡æ•°ã®æ§‹å›³æ¡ˆã‚’æŠ½å‡ºã™ã‚‹"""
    template = load_prompt_template("ThemeReaderMulti.txt")
    user_prompt = (
        template
        .replace("ã€Œ{input_text}ã€", input_text)
        .replace("ã€Œ{input_before}ã€", input_before)
        .replace("ã€Œ{input_after}ã€", input_after)
    )
    return call_gpt(user_prompt)

def run_theme_selector(input_text: str, candidates_text: str) -> str:
    """å€™è£œã®ä¸­ã‹ã‚‰ãƒ™ã‚¹ãƒˆæ§‹å›³ã‚’é¸ã¶"""
    template = load_prompt_template("ThemeSelector.txt")
    user_prompt = (
        template
        .replace("ã€Œ{input_text}ã€", input_text)
        .replace("ã€Œ{candidates_text}ã€", candidates_text)
    )
    return call_gpt(user_prompt)

def run_prompt_crafter(composition: str) -> str:
    template = load_prompt_template("PromptCrafter.txt")
    user_prompt = template.replace("ã€Œ{composition}ã€", composition)
    return call_gpt(user_prompt)


def run_image_critic(composition: str, image_info: str) -> str:
    template = load_prompt_template("ImageCritic.txt")
    user_prompt = (
        template
        .replace("ã€Œ{composition}ã€", composition)
        .replace("ã€Œ{image_info}ã€", image_info)
    )
    return call_gpt(user_prompt)


def run_image_improver(original_prompt: str, composition: str, feedback: str) -> str:
    template = load_prompt_template("ImageImprover.txt")
    user_prompt = (
        template
        .replace("ã€Œ{original_prompt}ã€", original_prompt)
        .replace("ã€Œ{composition}ã€", composition)
        .replace("ã€Œ{feedback}ã€", feedback)
    )
    return call_gpt(user_prompt)


def run_finalizer(composition: str, image_list: list[str], feedbacks: list[str]) -> str:
    template = load_prompt_template("Finalizer.txt")
    image_block = "\n".join([f"{i+1}: {img}" for i, img in enumerate(image_list)])
    feedback_block = "\n".join([f"{i+1}: {fb}" for i, fb in enumerate(feedbacks)])

    user_prompt = (
        template
        .replace("ã€Œ{composition}ã€", composition)
        .replace("ã€Œ{image_list}ã€", image_block)
        .replace("ã€Œ{feedbacks}ã€", feedback_block)
    )
    return call_gpt(user_prompt)

def generate_image(prompt: str, num_images: int = 1) -> list[Image.Image]:
    results = []
    for i in range(num_images):
        try:
            img = generate_sd_image(prompt, negative_prompt="(worst quality, low quality:1.3), poorly drawn face, poorly drawn hands, poorly drawn fingers, missing fingers, fused fingers, extra fingers, deformed fingers, bad hands, bad anatomy, lowres, text, error, extra limbs, missing arms, missing legs, mutation, mutated hands, bad proportions, cloned face, blurry, watermark, signature, censored, nsfw, nipples, cleavage, anime, cartoon, 3d, disfigured, jpeg artifacts, gross proportions, out of frame")
            results.append(img)
        except Exception as e:
            print(f"âŒ ç”»åƒç”Ÿæˆã«å¤±æ•—ï¼ˆ{i+1}/{num_images}ï¼‰: {e}")
            raise  # â† ã“ã“ã§å¿…ãšæ­¢ã‚ã‚‹
    return results
# ä¿®æ­£æ¸ˆã¿ generate_sd_image
def generate_sd_image(prompt: str, negative_prompt: str, port: int = 7860) -> Image.Image:
    

    print("âœ… generate_sd_image ã«å…¥ã£ãŸ")

    payload = {
        "prompt": prompt,
        "negative_prompt": negative_prompt,
        "model": "RealisticVisionXL_v57 [49E4F2939A]",
        "width": 1280,
        "height": 720,
        "steps": 45,
        "cfg_scale": 8.0,
        "sampler_index": "DPM++ 2M Karras",
    }

    url = f"http://127.0.0.1:{port}/sdapi/v1/txt2img"  # âœ… ã“ã“ã« port ã‚’åæ˜ 

    try:
        response = requests.post(url, json=payload, timeout=1500)
        print("ðŸ”µ ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹:", response.status_code)
        print("ðŸ”µ ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆ:", response.text[:500])  # é•·ã™ãŽã‚‹å ´åˆã®å¯¾ç­–

        r = response.json()
        print("ðŸ”µ JSONåž‹:", type(r))

        if not isinstance(r, dict):
            raise TypeError(f"JSON expected dict but got: {type(r)}\nå†…å®¹: {r}")

        images = r.get("images", [])
    except Exception as e:
        raise RuntimeError(f"ðŸš¨ SD APIå‘¼ã³å‡ºã— or JSONè§£æžã«å¤±æ•— â†’ {e}")

    if not images or not images[0].strip():
        raise RuntimeError(f"No usable image returned. SD API response: {r}")

    try:
        raw_image = images[0].strip()
        base64_data = raw_image.split(",", 1)[-1] if "," in raw_image else raw_image
        decoded = base64.b64decode(base64_data)
        image = Image.open(io.BytesIO(decoded))
        image.load()
        return image
    except Exception as e:
        raise RuntimeError(f"Base64 decode or Image.open failed â†’ {e}")

def get_image_for_scene(script_id: str, parent_id: str) -> Image.Image:
    print(f"ðŸš© get_image_for_scene CALLED with script_id={script_id}, parent_id={parent_id}")
    try:
        text = collect_text_for_scene(script_id, parent_id)
        print(f"ðŸ“ collected text: {text[:50]}...")  # é•·ã„å ´åˆç”¨ã«çœç•¥
        image = persona_pipeline(script_id, parent_id)
        print("âœ… persona_pipeline completed:", type(image))
        if not isinstance(image, Image.Image):
            raise TypeError(f"persona_pipeline did not return an Image: got {type(image)}")

        return image
    except Exception as e:
        print(f"ðŸ’¥ get_image_for_scene exception: {type(e).__name__}: {e}")
        raise  # ä¸Šä½ã® try ã«æ¸¡ã™

def get_all_parent_ids(script_id: str) -> list[str]:
    tag_path = Path(f"data_long/stage_2_tag/tags_{script_id}.json")
    if not tag_path.exists():
        raise FileNotFoundError(f"{tag_path} not found")
    with open(tag_path, "r", encoding="utf-8") as f:
        data = json.load(f)
        return [scene["parent_scene_id"] for scene in data["scenes"] if "parent_scene_id" in scene]


def persona_pipeline(script_id: str, parent_id: str) -> Image.Image:
    all_ids = get_all_parent_ids(script_id)
    center_index = all_ids.index(parent_id)

    before_id = all_ids[center_index - 1] if center_index > 0 else None
    after_id  = all_ids[center_index + 1] if center_index < len(all_ids) - 1 else None

    current_text = collect_text_for_scene(script_id, parent_id)
    before_text = collect_text_for_scene(script_id, before_id) if before_id else ""
    after_text  = collect_text_for_scene(script_id, after_id) if after_id else ""

    print("â‘  æ§‹å›³æŠ½å‡º é–‹å§‹ï¼ˆè¤‡æ•°æ¡ˆï¼‰")
    candidates_text = run_theme_reader_multi(current_text, before_text, after_text)
    print("â‘ -1 æ§‹å›³å€™è£œ æŠ½å‡ºå®Œäº†:\n", candidates_text)

    print("â‘ -2 ãƒ™ã‚¹ãƒˆæ§‹å›³é¸å®š é–‹å§‹")
    composition = run_theme_selector(current_text, candidates_text)
    print("â‘ -2 ãƒ™ã‚¹ãƒˆæ§‹å›³é¸å®š å®Œäº†:", composition)

    print("â‘¡ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ é–‹å§‹")
    prompt = run_prompt_crafter(composition)
    print("â‘¡ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ å®Œäº†:", prompt)

    print("â‘¢ åˆæœŸç”»åƒç”Ÿæˆ é–‹å§‹")
    images = generate_image(prompt, num_images=1)
    return images[0]  # â† ã“ã“ã ã‘ä¿®æ­£

    # # â‘£ è©•ä¾¡
    # feedbacks = [run_image_critic(composition, "N/A") for _ in images]
    # print("ðŸ“ åˆæœŸç”»åƒã«å¯¾ã™ã‚‹è©•ä¾¡:", feedbacks)

    # # â‘¤ æ”¹å–„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
    # improved_prompt = run_image_improver(prompt, composition, feedbacks[0])
    # print("ðŸ”§ æ”¹å–„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:", improved_prompt)  # â†â˜…è¿½åŠ 

    # # â‘¥ å†ç”Ÿæˆ
    # improved = generate_image(improved_prompt, num_images=1)
    # images += improved
    # feedbacks = [run_image_critic(composition, "N/A") for _ in images]

    # # â‘¦ æœ€çµ‚é¸å®š
    # final_choice = run_finalizer(composition, [f"Image {i+1}" for i in range(len(images))], feedbacks)

    # print(f"ðŸ” Final choice raw output: {final_choice}")

    # match = re.search(r'\d+', final_choice)
    # if match:
    #     index = int(match.group())
    #     print(f"âœ… Final image index selected: {index}")
    #     if 1 <= index <= len(images):
    #         selected = images[index - 1]
    #         if isinstance(selected, Image.Image):
    #             return selected
    #         else:
    #             raise TypeError(f"Selected item is not an image: {type(selected)}")
    #     else:
    #         raise ValueError(f"Image index out of bounds: {index} (images={len(images)})")
    # else:
    #     print("âš ï¸ No valid image number found in final_choice. Returning fallback image.")
    #     return images[0] if images else generate_blank_image()